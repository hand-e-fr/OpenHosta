{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "class ModelAnalizer:\n",
    "    \n",
    "    _default_name:str = \"Unknown\"\n",
    "    _default_input_cost:int = 0.005\n",
    "    _default_output_cost:int = 0.015\n",
    "    _default_token_perSec = 63.32\n",
    "    _default_latency = 0.48\n",
    "    _default_quality_score:int = 0\n",
    "    _default_security_score:int = 0\n",
    "    \n",
    "    def __init__(self, \n",
    "                 name:str,\n",
    "                 url:str,\n",
    "                 input_cost:float,\n",
    "                 output_cost:float, \n",
    "                 latency:float, \n",
    "                 token_perSec:float,\n",
    "                 quality_score:float,\n",
    "                 security_score:float\n",
    "                 ):\n",
    "        self.name = self._default_name if name is None else name\n",
    "        self.url = None if url is None else url\n",
    "        self.input_cost = self._default_input_cost if input_cost is None else input_cost\n",
    "        self.output_cost = self._default_output_cost if output_cost is None else output_cost\n",
    "        self.latency = self._default_latency if latency is None else latency\n",
    "        self.token_perSec = self._default_token_perSec if token_perSec is None else token_perSec\n",
    "        self.quality_score = self._default_quality_score if quality_score is None else quality_score\n",
    "        self.security_score = self._default_security_score if security_score is None else security_score\n",
    "        self.tokenizer = tiktoken.get_encoding(\"cl100k_base\")\n",
    "           \n",
    "    def get_name(self):\n",
    "        return self.name\n",
    "    \n",
    "    def get_url(self):\n",
    "        return self.url\n",
    "    \n",
    "    def get_input_cost(self):\n",
    "        return self.input_cost\n",
    "    \n",
    "    def get_output_cost(self):\n",
    "        return self.output_cost\n",
    "    \n",
    "    def get_latency(self):\n",
    "        return self.latency\n",
    "    \n",
    "    def get_token_perSec(self):\n",
    "        return self.token_perSec\n",
    "    \n",
    "    def get_quality_score(self):\n",
    "        return self.quality_score\n",
    "    \n",
    "    def get_security_score(self):\n",
    "        return self.security_score\n",
    "    \n",
    "    def is_url_correct(self):\n",
    "        return True\n",
    "    \n",
    "    def estimate_request_cost(self, input_text, estimated_output_token, model):\n",
    "        input_tokens = self.tokenizer.encode(input_text)\n",
    "        num_input_tokens = len(input_tokens)\n",
    "        num_output_tokens = estimated_output_token\n",
    "        cost_input = (num_input_tokens / 1000) * self.input_cost\n",
    "        cost_output = (num_output_tokens / 1000) * self.output_cost\n",
    "        total_cost = cost_input + cost_output\n",
    "        return total_cost\n",
    "        \n",
    "Models:dict = {\n",
    "    \"BEST\": ModelAnalizer(name=\"gpt-4o\", url=\"url\", input_cost=0.005, output_cost=0.015, latency=0.48, token_perSec=63.32, quality_score=1, security_score=0.2),\n",
    "    # \"FAST\": ModelAnalizer(name=\"gpt-4o\", url=\"url\", input_cost=0.005, output_cost=0.015, latency=0.48, token_perSec=63.32, quality_score=1, security_score=0.2),\n",
    "    # \"CHEAP\": ModelAnalizer(name=\"gpt-4o\", url=\"url\", input_cost=0.005, output_cost=0.015, latency=0.48, token_perSec=63.32, quality_score=1, security_score=0.2),\n",
    "    \"SECURE\": ModelAnalizer(name=\"gpt-4o\", url=\"url\", input_cost=0.005, output_cost=0.015, latency=0.48, token_perSec=63.32, quality_score=1, security_score=0.2),\n",
    "    }\n",
    "    \n",
    "print(Models[\"BEST\"].get_name())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
