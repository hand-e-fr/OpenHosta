{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/hand-e-fr/OpenHosta/blob/doc/docs/openhosta_phi4_mini.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ywSpiksruBs"
   },
   "source": [
    "# OpenHosta basic example with a Local Phi4-mini\n",
    "\n",
    "This colab demonstrate simple use cases of OpenHosta. If you do not have an OpenAI (or other) API KEY, you can run the first part **Install a local Phi-4-mini**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DjZKsvksUPf"
   },
   "source": [
    "## Install Openhosta with a local Phi-4-mini model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5NCvoTi3phgq",
    "outputId": "977e1c10-dbc1-4f8c-fea7-0577836ffae6"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt install -y screen\n",
    "!curl -L https://github.com/ollama/ollama/releases/download/v0.5.13-rc4/ollama-linux-amd64.tgz -o ollama-linux-amd64.tgz\n",
    "!sudo tar -C /usr -xzf ollama-linux-amd64.tgz\n",
    "# Load and run the model:\n",
    "!screen -dmS ollama ollama serve\n",
    "# Can take 5 minutes\n",
    "!ollama run phi4-mini hello --verbose  2>&1 | grep -E \"([^0]0%|Bonjour|:)\"\n",
    "!pip install OpenHosta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0x6AUM3osYK2"
   },
   "source": [
    "## Basic Usage of OpenHosta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ZEB71Ytsk4B"
   },
   "source": [
    "### Configure the LLM that you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "SBC5-L0zqH1c"
   },
   "outputs": [],
   "source": [
    "from OpenHosta import config\n",
    "\n",
    "# If you have an OpenAI API key you can use it like this:\n",
    "# Use default model (gpt-4o) through API key\n",
    "# config.set_default_apiKey(<<YOUR API KEY>>)\n",
    "\n",
    "# Comment this if you use OpenAI models\n",
    "# Use Microsoft local Phi-4 through ollama\n",
    "my_model=config.OpenAICompatibleModel(\n",
    "    base_url=\"http://localhost:11434/v1/chat/completions\",\n",
    "    model=\"phi4-mini\", api_key=\"none\", timeout=120\n",
    ")\n",
    "config.set_default_model(my_model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FauFveKWsp3G"
   },
   "source": [
    "### Emulate functions using the seleted LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "SEpo1gfJT8Bg"
   },
   "outputs": [],
   "source": [
    "from OpenHosta import emulate_async"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gE1ecyDzUVFE",
    "outputId": "35a8a881-6ea3-4501-a7a0-85cde7ccabe3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour le monde!\n"
     ]
    }
   ],
   "source": [
    "async def translate(text:str, language:str)->str:\n",
    "    \"\"\"\n",
    "    This function translates the text in the “text” parameter into the language specified in the “language” parameter.\n",
    "    \"\"\"\n",
    "    return await emulate_async()\n",
    "\n",
    "result = await translate(\"Hello World!\", \"French\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "avGsfrxQUsCb"
   },
   "outputs": [],
   "source": [
    "# You can select another model like this\n",
    "#my_model = config.OpenAICompatibleModel(\n",
    "#    model=\"gpt-4o-mini\",\n",
    "#    base_url=\"https://api.openai.com/v1/chat/completions\",\n",
    "#    api_key=<<API KEY>>\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I_AJQzoKU192",
    "outputId": "a8a937bf-28bb-46c6-e8eb-b0d5e7ce3a7e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'dict', 'data': {'name': 'John Wick', 'age': '30'}}\n"
     ]
    }
   ],
   "source": [
    "async def find_name_age(sentence:str, id:dict)->dict:\n",
    "    \"\"\"\n",
    "    This function find in a text the name and the age of a personn.\n",
    "\n",
    "    Args:\n",
    "        sentence: The text in which to search for information\n",
    "        id: The dictionary to fill in with information\n",
    "\n",
    "    Return:\n",
    "        A dictionary identical to the one passed in parameter, but filled with the information.\n",
    "        If the information is not found, fill with the values with “None”.\n",
    "    \"\"\"\n",
    "    return await emulate_async(model=my_model)\n",
    "\n",
    "return_dict = {\"name\": \"\", \"age\": \"\"}\n",
    "result = await find_name_age(\"Hello, I'm John Wick, i'm 30 and I live in New York\", return_dict)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bVuS-CC6szQM"
   },
   "source": [
    "### Specify advanced return types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXiKTdYm_GGp",
    "outputId": "c96a8edd-3b5e-4f63-ec84-0ab2be90875f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'type': 'object', 'wordAnalysis': [{'length': 6, 'word': ['Hello']}, {'length': 1, 'word': [',']}]}\n",
      "<class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Tuple, List\n",
    "\n",
    "async def analyze_text(text: str) -> Dict[str, List[Tuple[int, str]]]:\n",
    "    \"\"\"Analyze text to map each word to a list of tuples containing word length and word.\"\"\"\n",
    "    return await emulate_async()\n",
    "\n",
    "# Example usage\n",
    "analysis = await analyze_text(\"Hello, World!\")\n",
    "\n",
    "print(analysis)\n",
    "print(type(analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5qFAS06s7Eq"
   },
   "source": [
    "### Specify pydantic return strucures\n",
    "\n",
    "OpenHosta is compatible with pydantic. You can specify pydantic input and output types and OpenHosta will propagate schema and Field documentation to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-w2PyozHrklT",
    "outputId": "40c8bb28-8962-41b3-d41c-470289407fe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (2.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic) (4.12.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnn5ed4QWXYs",
    "outputId": "ff0a8f76-cd5a-40ef-ef4c-dd3213117d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'properties': {'name': {'description': 'The full name', 'title': 'Name', 'type': 'string'}, 'age': {'title': 'Age', 'type': 'integer'}}, 'required': ['name', 'age'], 'title': 'Personn', 'type': 'object'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[TypeConverter.check]: Failed to convert pydantic type from the LLM. Keep original type.\n"
     ]
    }
   ],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class Personn(BaseModel):\n",
    "    name: str = Field(..., description = \"The full name\")\n",
    "    age: int\n",
    "\n",
    "async def find_name_age_pydantic(sentence:str)->Personn:\n",
    "    \"\"\"\n",
    "    This function find in a text the name and the age of a personn.\n",
    "\n",
    "    Args:\n",
    "        sentence: The text in which to search for information\n",
    "\n",
    "    Return:\n",
    "        A Pydantic model, but filled with the information.\n",
    "        If the information is not found, fill with the values with “None”.\n",
    "    \"\"\"\n",
    "    return await emulate_async()\n",
    "\n",
    "result = await find_name_age_pydantic(\"Luke Skywalker is very surprising: he's only 27 when he becomes a Jedi.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VvcHBChjtyys"
   },
   "source": [
    "### Limitations\n",
    "\n",
    "The emulation is limited by the LLM capabilities. Try to have it count r in strawberrry and you will get into troubles ;-).\n",
    "Make sure the LLM is capable and not alucinating before you implement an emulated function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E5eTPiUyXjXR",
    "outputId": "0f1ab313-9af7-44af-9e60-14d917016ab5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "async def find_occurence_of_a_word(word :str, text: str) -> int:\n",
    "    \"\"\"\n",
    "    This function takes a word and a text and returns\n",
    "    the number of times the word appears in the text.\n",
    "    \"\"\"\n",
    "    return await emulate_async()\n",
    "\n",
    "await find_occurence_of_a_word(\"Hello\", \"Hello World Hello!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can call async or sync version of emulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from OpenHosta import emulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_occurence_of_a_word(word :str, text: str) -> int:\n",
    "    \"\"\"\n",
    "    This function takes a word and a text and returns\n",
    "    the number of times the word appears in the text.\n",
    "    \"\"\"\n",
    "    return emulate()\n",
    "\n",
    "find_occurence_of_a_word(\"Hello\", \"Hello World Hello!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
