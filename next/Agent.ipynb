{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hand-e-fr/OpenHosta/blob/3.0.0_beta1/OpenHosta/tree/3.0.0_beta1/docs/SmokeTest_ollama.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Instal OpenHosta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install --upgrade -qqq uv\n",
        "\n",
        "# If you need to test a pre release uncomment:\n",
        "VERSION=\"@3.0.1\"\n",
        "\n",
        "!uv pip install -U \\\n",
        "    \"git+https://github.com/hand-e-fr/OpenHosta.git$VERSION\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install Ollama\n",
        "\n",
        "This is to run a local model and have zero dependancies to externa API provides."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PfTzrCGKc8eG",
        "outputId": "31287fb2-e5a7-4c3f-d6e9-96a32de27d5f"
      },
      "outputs": [],
      "source": [
        "# This seems not to be accepted by google colab anymore. \n",
        "# Run it in a separtated terminal i refused\n",
        "#!apt install -y screen\n",
        "#!curl -fsSL https://ollama.com/install.sh | sh\n",
        "#!screen -dmS ollama ollama serve\n",
        "\n",
        "# So we just show how to install Ollama on linux\n",
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We test is ollama is available and how fast Qwen3 runs on it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "i1st6ZJpdGn0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We\u001b[?25l\u001b[?25h have\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h user\u001b[?25l\u001b[?25h:\u001b[?25l\u001b[?25h \"\u001b[?25l\u001b[?25hhello\u001b[?25l\u001b[?25h\".\u001b[?25l\u001b[?25h They\u001b[?25l\u001b[?25h greet\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h We\u001b[?25l\u001b[?25h should\u001b[?25l\u001b[?25h respond\u001b[?25l\u001b[?25h politely\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Use\u001b[?25l\u001b[?25h friendly\u001b[?25l\u001b[?25h tone\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h It's\u001b[?25l\u001b[?25h a\u001b[?25l\u001b[?25h simple\u001b[?25l\u001b[?25h greeting\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h Probably\u001b[?25l\u001b[?25h ask\u001b[?25l\u001b[?25h how\u001b[?25l\u001b[?25h I\u001b[?25l\u001b[?25h can\u001b[?25l\u001b[?25h help\u001b[?25l\u001b[?25h.\u001b[?25l\u001b[?25h\n",
            "total duration:       724.45224ms\n",
            "load duration:        281.59815ms\n",
            "prompt eval count:    68 token(s)\n",
            "prompt eval duration: 71.126712ms\n",
            "prompt eval rate:     956.04 tokens/s\n",
            "eval count:           53 token(s)\n",
            "eval duration:        370.899835ms\n",
            "eval rate:            142.90 tokens/s\n"
          ]
        }
      ],
      "source": [
        "!ollama run gpt-oss:20b hello --verbose  2>&1 | grep -E \":\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Use OpenHosta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "YJzVlcvjbf38"
      },
      "outputs": [],
      "source": [
        "\n",
        "from OpenHosta import config\n",
        "\n",
        "# You can replace with your own API (OpenAI chat/completion compatble)\n",
        "config.DefaultModel.base_url = \"http://localhost:11434/v1\"\n",
        "config.DefaultModel.model_name = \"gpt-oss:20b\"\n",
        "config.DefaultModel.api_key = \"not used by ollama local api\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**We test that the API is working with a simple call**\n",
        "\n",
        "`ask()` makes a very simple call to the API without adding any hidden prompt.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'Hello! 👋 How can I help you today?'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from OpenHosta import ask\n",
        "\n",
        "ask(\"Hello World!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Build a workflow agent\n",
        "\n",
        "Let's see how to impement an agent with memory within an object"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "import asyncio\n",
        "from dataclasses import dataclass\n",
        "from OpenHosta.asynchrone import emulate, closure\n",
        "\n",
        "from enum import Enum\n",
        "\n",
        "class SubjectsInMemoryStore(Enum):\n",
        "    FamilyMemberLinks = \"FamilyMemberLinks\"\n",
        "    PeopleNames = \"PeopleNames\"\n",
        "    Grocery = \"Grocery\"\n",
        "    CalendarEvents = \"CalendarEvents\"\n",
        "    NotValidSubject = \"NotValidSubject\"\n",
        "    \n",
        "class ActionType(Enum):\n",
        "    INSERT=\"INSERT\"\n",
        "    UPDATE=\"UPDATE\"\n",
        "    DELETE=\"DELETE\"\n",
        "    SELECT=\"SELECT\"\n",
        "    \n",
        "    \n",
        "@dataclass\n",
        "class UserDetails:\n",
        "    FirstName: str\n",
        "    LastName: str\n",
        "    Age: int\n",
        "\n",
        "class MyAgentWithMemory:\n",
        "    \"\"\"\n",
        "    This agent records elements from the conversation only if they are related to specific subkects\n",
        "    \"\"\"\n",
        "    \n",
        "    CurrentUserId:str = None\n",
        "    MemoryElements:dict = {}\n",
        "    \n",
        "    ChatLogs = []\n",
        "    \n",
        "    async def is_about_element_that_we_record(self, sentence: str) -> SubjectsInMemoryStore:\n",
        "        \"\"\"\n",
        "        This function takes a sentenc and identify if there is element to record.\n",
        "        \n",
        "        We only record elements on subjects that we are allowed to.\n",
        "\n",
        "        Args:\n",
        "            sentence (str): a snippet of text from a conversation\n",
        "\n",
        "        Returns:\n",
        "            SubjectsInMemoryStore: In what category to store if we store something\n",
        "        \"\"\"\n",
        "        # UserName variable and value will be worwarded to the LLM\n",
        "        SpeakerName=self.MemoryElements.get(SubjectsInMemoryStore.PeopleNames, {}).get(self.CurrentUserId)\n",
        "        return await emulate()\n",
        "    \n",
        "    async def detect_action_type(self, sentence:str) -> ActionType:\n",
        "        \"\"\"\n",
        "        Identify the type of action that is implicitly requested in the sentence.\n",
        "        \n",
        "        The sentence is produced by us user of our system. Our system has a memory.\n",
        "        What action should be do on our memory to best answer user expectations?\n",
        "        \n",
        "        Return:\n",
        "            ActionType\n",
        "        \"\"\"\n",
        "        return await emulate() \n",
        "        \n",
        "    async def is_telling_who_he_is(self, sentence:str) -> bool:\n",
        "        \"\"\"\n",
        "        The speaker is telling about who he is in this sentence.\n",
        "\n",
        "        Args:\n",
        "            sentence (str): a sentence made by a speaker\n",
        "\n",
        "        Returns:\n",
        "            bool: True if we learn about his name or forstname\n",
        "        \"\"\"\n",
        "        return await emulate()\n",
        "    \n",
        "    async def fill_user_details(self, sentence:str, previouse_details:UserDetails)->UserDetails:\n",
        "        \"\"\"\n",
        "        Identifies data fields from the sentence\n",
        "\n",
        "        Args:\n",
        "            sentence (_type_): what the user say\n",
        "            previouse_details: What we new about this user\n",
        "            \n",
        "        Return:\n",
        "            Filled UserDetails object for this user\n",
        "        \"\"\"\n",
        "        return await emulate()\n",
        "    \n",
        "    \n",
        "    async def answer_to(self, sentence:str)->str:\n",
        "        \"\"\"\n",
        "        Proces the use input, handle memory, than answer.\n",
        "\n",
        "        Args:\n",
        "            sentence (str): what the client say\n",
        "\n",
        "        Returns:\n",
        "            str: what the agent answers\n",
        "        \"\"\"\n",
        "        if self.CurrentUserId is None:\n",
        "            tells_who_he_is = await self.is_telling_who_he_is(sentence)\n",
        "            print(tells_who_he_is)\n",
        "            if tells_who_he_is:\n",
        "                who = await self.fill_user_details(sentence, None)\n",
        "                self.CurrentUserId = \"you\"\n",
        "                if SubjectsInMemoryStore.PeopleNames not in self.MemoryElements:\n",
        "                    self.MemoryElements[SubjectsInMemoryStore.PeopleNames] = {}\n",
        "                self.MemoryElements.get(SubjectsInMemoryStore.PeopleNames)[self.CurrentUserId] = who\n",
        "                \n",
        "                return await self.format_answer(\"user name recoded\", who, sentence)\n",
        "            else:\n",
        "                return await self.format_answer(\"user shall identify first\", None, sentence)\n",
        "        else:\n",
        "            return await self.process_question(sentence)\n",
        "            \n",
        "        \n",
        "    async def find_first_element(self, subject:SubjectsInMemoryStore, question:str):\n",
        "        \"\"\"\n",
        "        Find who we are speaking aabout\n",
        "\n",
        "        Args:\n",
        "            question (str): question\n",
        "        \"\"\"\n",
        "        async def is_target(subject, question, key, value)->bool:\n",
        "            \"\"\"\n",
        "            Decide if the suject that is refered to by the question is the one described by key:value.\n",
        "            \n",
        "            If it is clear that we speak about this one, return True.\n",
        "            Otherwise return False.\n",
        "            \"\"\"\n",
        "            return await emulate()\n",
        "        \n",
        "        for k,v in self.MemoryElements.items():\n",
        "            print(f\"Look: {k}, {v}\")\n",
        "            if await is_target(subject, question, k, v):\n",
        "                print(\"FOUND: \", k, v)\n",
        "                return k, v\n",
        "            \n",
        "        return None, None\n",
        "            \n",
        "    async def format_answer(self, instruction, data, question)->str:\n",
        "        \"\"\"\n",
        "        Format a written answer to the question knowing that have executed `instruction` on 'data'.\n",
        "\n",
        "        Args:\n",
        "            instruction (_type_): what we have done or that we want to tell the user that we have done\n",
        "            data (_type_): the data found, inserted or modified\n",
        "            question (_type_): wht the used originally asked for.\n",
        "\n",
        "        Returns:\n",
        "            str: what we say to the user as an answer to his question\n",
        "        \"\"\"\n",
        "        return await emulate()\n",
        "        \n",
        "        \n",
        "    async def process_question(self, question):\n",
        "        \"\"\"\n",
        "        This is the main logic for thiw workflow agent\n",
        "\n",
        "        Args:\n",
        "            question (str): user question\n",
        "        \"\"\"\n",
        "        subject, action  = await asyncio.gather(\n",
        "            self.is_about_element_that_we_record(question),\n",
        "            self.detect_action_type(question)\n",
        "        )\n",
        "        print(subject, action)\n",
        "\n",
        "        if subject is SubjectsInMemoryStore.NotValidSubject:\n",
        "            return await self.format_answer(\"this suject is not handeled by this assistant\", action, question)\n",
        "\n",
        "        if action is ActionType.INSERT:\n",
        "            if subject is SubjectsInMemoryStore.PeopleNames:      \n",
        "                who_name, details = await asyncio.gather(\n",
        "                    closure(\"return a name for the person that we shall remember\")(question),\n",
        "                    self.fill_user_details(question, None)\n",
        "                )                \n",
        "                data = self.MemoryElements.get(SubjectsInMemoryStore.PeopleNames, {})[who_name] = details\n",
        "                return await self.format_answer(\"we have recorded the people\", data, question )\n",
        "                \n",
        "            else:\n",
        "                what_name, what_desc = await asyncio.gather(\n",
        "                    closure(\"return a name for the element that we shall remember\")(question),\n",
        "                    closure(\"return a description of the element that we shall remember\")(question)\n",
        "                )\n",
        "                if subject not in self.MemoryElements:\n",
        "                    self.MemoryElements[subject] = {}\n",
        "                self.MemoryElements.get(subject)[what_name] = what_desc\n",
        "                return await self.format_answer(\"we have recorded the element\", what_desc, question )\n",
        "                \n",
        "        elif action is ActionType.SELECT:\n",
        "            key, data = await self.find_first_element(subject, question)\n",
        "            \n",
        "            if key is None:\n",
        "                return await self.format_answer(\"we have not found the element in out knowledge\", None, question )\n",
        "                \n",
        "            print(\"FOUND: \", key, data)\n",
        "            return await self.format_answer(\"we have found the element in out knowledge\", {\"key\":key, \"data\":data}, question)\n",
        "            \n",
        "        else:\n",
        "            return await self.format_answer(\"action not yet supported\", action, question)\n",
        "            \n",
        "        \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "A=MyAgentWithMemory()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SubjectsInMemoryStore.PeopleNames ActionType.INSERT\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Bonjour Emmanuel, nous avons enregistré vos informations.'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await A.answer_to(\"bonjour, je suis emmanuel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SubjectsInMemoryStore.NotValidSubject ActionType.SELECT\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Je suis désolé, mais ce sujet n'est pas pris en charge par cet assistant.\""
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await A.answer_to(\"Quelle sera la météo demain ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SubjectsInMemoryStore.NotValidSubject ActionType.SELECT\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I’m sorry, I’m not able to answer that question.'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await A.answer_to(\"Qui es-tu ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SubjectsInMemoryStore.NotValidSubject ActionType.SELECT\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Je suis désolé, mais ce sujet ne relève pas de mes compétences.'"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await A.answer_to(\"Qui suis-je ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SubjectsInMemoryStore.PeopleNames ActionType.INSERT\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I have recorded the details: First Name\\u202f=\\u202fEmmanuel, Last Name\\u202f=\\u202fBatt, Age\\u202f=\\u202f42.'"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await A.answer_to(\"Je suis emmanuel batt. mémorise cela. je suis né en 1983\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{<SubjectsInMemoryStore.PeopleNames: 'PeopleNames'>: {'you': UserDetails(FirstName='Emmanuel', LastName='', Age=0),\n",
              "  'Emmanuel': UserDetails(FirstName='emmanuel', LastName='', Age=0),\n",
              "  'Emmanuel Batt': UserDetails(FirstName='emmanuel', LastName='batt', Age=42)},\n",
              " <SubjectsInMemoryStore.Grocery: 'Grocery'>: {'bread_purchase': \"C'est une phrase indiquant la nécessité d'acheter du pain.\"}}"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "A.MemoryElements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SubjectsInMemoryStore.Grocery ActionType.INSERT\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'You asked, “Il faut acheter du pain.”  \\nWe have recorded the following element: **C’est une phrase indiquant la nécessité d’acheter du pain.**'"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await A.answer_to(\"Il faut acheter du pain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SubjectsInMemoryStore.Grocery ActionType.SELECT\n",
            "Look: SubjectsInMemoryStore.PeopleNames, {'you': UserDetails(FirstName='Emmanuel', LastName='', Age=0), 'Emmanuel': UserDetails(FirstName='emmanuel', LastName='', Age=0), 'Emmanuel Batt': UserDetails(FirstName='Emmanuel', LastName='Batt', Age=0)}\n",
            "Look: SubjectsInMemoryStore.Grocery, {'bread_purchase': \"C'est une phrase indiquant la nécessité d'acheter du pain.\"}\n",
            "FOUND:  SubjectsInMemoryStore.Grocery {'bread_purchase': \"C'est une phrase indiquant la nécessité d'acheter du pain.\"}\n",
            "FOUND:  SubjectsInMemoryStore.Grocery {'bread_purchase': \"C'est une phrase indiquant la nécessité d'acheter du pain.\"}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Vous devez acheter du pain.'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await A.answer_to(\"Que faut il acheter ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SubjectsInMemoryStore.Grocery ActionType.SELECT\n",
            "Look: SubjectsInMemoryStore.PeopleNames, {'you': UserDetails(FirstName='Emmanuel', LastName='', Age=0), 'Emmanuel': UserDetails(FirstName='emmanuel', LastName='', Age=0), 'Emmanuel Batt': UserDetails(FirstName='emmanuel', LastName='batt', Age=42)}\n",
            "Look: SubjectsInMemoryStore.Grocery, {'bread_purchase': \"C'est une phrase indiquant la nécessité d'acheter du pain.\"}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I’m sorry, but I couldn’t find any information in my knowledge to answer whether you should buy water.'"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await A.answer_to(\"Faut il acheter de l'eau ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SubjectsInMemoryStore.Grocery ActionType.SELECT\n",
            "Look: SubjectsInMemoryStore.PeopleNames, {'you': UserDetails(FirstName='Emmanuel', LastName='', Age=0), 'Emmanuel': UserDetails(FirstName='emmanuel', LastName='', Age=0), 'Emmanuel Batt': UserDetails(FirstName='emmanuel', LastName='batt', Age=42)}\n",
            "Look: SubjectsInMemoryStore.Grocery, {'bread_purchase': \"C'est une phrase indiquant la nécessité d'acheter du pain.\"}\n",
            "FOUND:  SubjectsInMemoryStore.Grocery {'bread_purchase': \"C'est une phrase indiquant la nécessité d'acheter du pain.\"}\n",
            "FOUND:  SubjectsInMemoryStore.Grocery {'bread_purchase': \"C'est une phrase indiquant la nécessité d'acheter du pain.\"}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'Oui, il faut acheter du pain.'"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "await A.answer_to(\"Faut-il acheter du pain ?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "System prompt:\n",
            "-----------------\n",
            "You will act as a simulator for functions that cannot be implemented in actual code.\n",
            "\n",
            "I'll provide you with function definitions described in Python syntax. \n",
            "These functions will have no body and may even be impossible to implement in real code, \n",
            "so do not attempt to generate the implementation.\n",
            "\n",
            "Instead, imagine a realistic or reasonable output that matches the function description.\n",
            "I'll ask questions by directly writing out function calls as one would call them in Python.\n",
            "Respond with an appropriate return value, without adding any extra comments or explanations.\n",
            "If the provided information isn't enough to determine a clear answer, respond simply with \"None\".\n",
            "If assumptions need to be made, ensure they stay realistic, align with the provided description.\n",
            "\n",
            "Here's the function definition:\n",
            "\n",
            "```python\n",
            "<class 'str'>\n",
            "\n",
            "def format_answer(self, instruction, data, question) -> str:\n",
            "    \"\"\"\n",
            "        Format a written answer to the question knowing that have executed `instruction` on 'data'.\n",
            "\n",
            "        Args:\n",
            "            instruction (_type_): what we have done or that we want to tell the user that we have done\n",
            "            data (_type_): the data found, inserted or modified\n",
            "            question (_type_): wht the used originally asked for.\n",
            "\n",
            "        Returns:\n",
            "            str: what we say to the user as an answer to his question\n",
            "        \"\"\"\n",
            "\n",
            "    ...\n",
            "    ...behavior to be simulated...\n",
            "    ...\n",
            "\n",
            "    return ...appropriate return value...\n",
            "```\n",
            "\n",
            "User prompt:\n",
            "-----------------\n",
            "# Values of parameters to be used\n",
            "self=<__main__.MyAgentWithMemory object at 0x7e6fba3a8bf0>\n",
            "\n",
            "instruction='we have found the element in out knowledge'\n",
            "\n",
            "data={'key': <SubjectsInMemoryStore.Grocery: 'Grocery'>, 'data': {'bread_purchase': \"C'est une phrase indiquant la nécessité d'acheter du pain.\"}}\n",
            "\n",
            "question='Faut-il acheter du pain ?'\n",
            "\n",
            "format_answer(self, instruction, data, question)\n",
            "LLM response:\n",
            "-----------------\n",
            "Oui, il faut acheter du pain.\n"
          ]
        }
      ],
      "source": [
        "from OpenHosta import print_last_prompt\n",
        "print_last_prompt(A.format_answer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNhsodrHnwmlJ7/0yYQTF1p",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "VSCode_GitRepos",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
